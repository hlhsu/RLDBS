
# -*- coding: utf-8 -*-
"""Baseline_model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ldOwVn0vFi0400h3ViGI-oQnl8SKR_yN
"""

import gym
import gym_oscillator

from stable_baselines3.common.utils import set_random_seed


from stable_baselines3.common.env_util import make_vec_env
import random
import numpy as np
from matplotlib import pyplot as plt
import time

from stable_baselines3.common.noise import NormalActionNoise, OrnsteinUhlenbeckActionNoise#, AdaptiveParamNoiseSpec
from stable_baselines3 import PPO

import argparse


parser = argparse.ArgumentParser()
parser.add_argument('--algo', type = str, default = 'SAC')
parser.add_argument('--core', type = int, default = 1) # only PPO is supported with multiple cores
parser.add_argument('--seed', type = int, default = 0)
parser.add_argument('--model_folder', type = str, default = 'trained_models')
parser.add_argument('--exp_name', type = str, default = '_exp_1000_pytorch_test') # ppo: '_exp_1000_pytorch_v2'
parser.add_argument('--time_steps', type = int, default = 1e7) # 5000000 #1e7
args = parser.parse_args()













if __name__ == '__main__':


    env_id = 'oscillator-v0'
    time_steps = args.time_steps # 10e7 #5000000
    num_cpu = args.core
    seed = args.seed


    set_random_seed(seed)
    np.random.seed(seed)
 
    random.seed(seed)


    
    start = time.time()


    # from stable_baselines3 import PPO
    import torch
   
    env_id = 'oscillator-v0'
    env = gym.make(env_id)
    #Number of cpus
    num_cpu = 1
    

 
 
    print('start to load model')
    print('load process')
    model = PPO.load("trained_models/PPO_exp_1000_pytorch0")
    print('finish loading')
    
    
    #Store rewards
    rews_ = []
    #Store observations
    obs_ = []
    obs = env.reset()
    #Store actions
    acs_ = []
    #Store X,Y according to 
    states_x = []
    states_y = []

    abs_action = []

    abs_min = 1
    abs_max =0
    
    #Initial, non-suppresssion 
    TT=7500
    for i in range(TT):

      
        obs, rewards, dones, info = env.step([0])
       
        states_x.append(env.x_val)
        states_y.append(env.y_val)
        obs_.append(obs[0])
        acs_.append(0)
        rews_.append(rewards)
    
    #Suppression stage
    for i in range(TT):

        
        action, _states = model.predict(obs)

       
        obs, rewards, dones, info = env.step(action)

      
        states_x.append(env.x_val)
        states_y.append(env.y_val)
        obs_.append(obs[0])
        acs_.append(action)
        rews_.append(rewards)
    
    #Final relaxation
    for i in range(5000):
        obs, rewards, dones, info = env.step([0])
        states_x.append(env.x_val)
        states_y.append(env.y_val)
        obs_.append(obs[0])
        acs_.append(0)
        rews_.append(rewards)




    # ######################################################################33    
        
    '''state action plot '''
    plt.figure(figsize=(12,3))   
    ax = plt.subplot()  
    # ax.spines["top"].set_visible(False)  
    # ax.spines["right"].set_visible(False)  
    ax.get_xaxis().tick_bottom()    
    ax.get_yaxis().tick_left()    
    plt.xticks(fontsize=18)
    plt.yticks(fontsize=18) 
    # plt.figure(figsize=(12,3))    
    plt.plot(states_x,lw=2, color = 'darkslateblue')
    ax.set_ylabel('X(t)', fontsize=20, color = 'darkslateblue') 
    ax.tick_params(axis='y')
    ax2 = ax.twinx() 
    ax2.set_ylabel('Action', fontsize=20, color='lightseagreen') 
    plt.plot(acs_, color='lightseagreen', lw=2)
    plt.yticks(fontsize= 18)
    ax2.set_ylim(-1.0,2.0)
    plt.title('Synchrony Supression of PPO', fontsize = 26)
    plt.savefig('StateActionnewPPO_test.png')
    
  
